---
layout: post
title: T5(ì£¼ìš” í¬ì¸íŠ¸ ìœ„ì£¼) + mt5 ì½”ë“œ êµ¬í˜„
tags: [t5,mt5,íŠ¸ëœìŠ¤í¬ë¨¸]
comments: true
---



## T5 (êµµì§êµµì§í•œ í¬ì¸íŠ¸ ì„¸ ê°€ì§€ + íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œ ë°”ë€ ì )

ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ìµœê·¼ ê¸°ê³„ë²ˆì—­ ëŒ€íšŒë¥¼ ì¤€ë¹„í•˜ë©´ì„œ ì´ëŸ° ì €ëŸ° ëª¨ë¸ì„ ê³µë¶€í•˜ê³  í•œë²ˆ ì‹¤ìŠµí•´ë³´ê³  ìˆìŠµë‹ˆë‹¤. ì œê°€ ì´ë²ˆì— ê³µë¶€í•œ ë…¼ë¬¸ì€ **T5** ì¸ë°ìš”. í•œë²ˆ ì œê°€ ì‚´í´ë³¸ T5ì˜ ì¤‘ìš” í¬ì¸íŠ¸ ìœ„ì£¼ë¡œ ì •ë¦¬í•´ë³´ê² ìŠµë‹ˆë‹¤. (ì‚¬ì‹¤ ë…¼ë¬¸ì´ 62í˜ì´ì§€? ê°€ëŸ‰ ë˜ì–´ì„œ ë¦¬ë·° ê¸€ë¡œ ê³µë¶€í•˜ê³  ìˆì„ ë¿ ì •í™•í•˜ê²Œ ê³µë¶€í•  ì—„ë‘ë„ ëª» ë‚´ê³  ìˆìŠµë‹ˆë‹¤ ğŸ˜¨)

### 1. Text to Text í˜•ì‹ì„ ì‚¬ìš©í•˜ë©´ ê°ê°ì˜ downstream task ì— ì¼ì¼ì´ íŒŒì¸íŠœë‹í•  í•„ìš”ê°€ ì—†ì§€ ì•Šì„ê¹Œ ? 

ì €ëŠ” ìµœê·¼ê¹Œì§€ë„ downstream task, upstream task, pretrain, fine tuning ë“±ë“±ì˜ ìš©ì–´ê°€ ëª¹ì‹œ í–‡ê°ˆë ¤ì„œ 'í•œêµ­ì–´ ì„ë² ë”©' ì´ë¼ëŠ” ì±…ì„ í†µí•´ì„œ ì •ë¦¬í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. 

**Pretrain** : ëŒ€ê·œëª¨ ë§ë­‰ì¹˜ë¡œ ì„ë² ë”©ì„ ë§Œë“ ë‹¤

**Fine-tuning / Transfer learning** : ì´í›„ ì„ë² ë”©ì„ ì…ë ¥ìœ¼ë¡œ í•˜ëŠ” ìƒˆë¡œìš´ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ê³  í’€ê³  ì‹¶ì€ êµ¬ì²´ì  ë¬¸ì œì— ë§ëŠ” ì†Œê·œëª¨ ë°ì´í„°ì— ë§ê²Œ ì„ë² ë”©ì„ í¬í•¨í•œ ëª¨ë¸ ì „ì²´ë¥¼ ì—…ë°ì´íŠ¸í•œë‹¤.  - 'í•œêµ­ì–´ ì„ë² ë”©'

êµ¬ì²´ì ìœ¼ë¡œ, fine-tuning ê³¼ transfer learning ì˜ ì°¨ì´ì— ëŒ€í•´ì„œë„ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. 

**<u>Transfer learning</u> is when a model developed for one task is reused to work on a second task. <u>Fine tuning</u> is one approach to transfer learning.**

**In Fine-tuning, an approach of Transfer Learning, we have a dataset, and we use let's say 90% of it in training. Then we train the same model with the remaining 10%. Usually, we change the learning rate to a smaller one, so it does not have a significant impact on the already adjusted weights. You can consider the case I said (90% to train, 10% fine-tune) as transfer learning by fine-tuning, where the 10% could have data from a different nature, or simply one different class.**

ì œê°€ ë”±íˆ ë§¤ë„ëŸ½ê²Œ ë²ˆì—­í•  ìˆ˜ ìˆì„êº¼ ê°™ì§€ ì•Šì•„ì„œ ì› ì •ë³´ ê·¸ëŒ€ë¡œ ì˜¬ë ¸ìŠµë‹ˆë‹¤ ;; nlp ì—ì„œëŠ” ì„ë² ë”©ì´ë¼ëŠ” ëª©í‘œë¥¼ ìœ„í•´ ì—¬ëŸ¬ pre-training task ë¡œ í•™ìŠµëœ ì–¸ì–´ëª¨ë¸ì„ ë‹¤ìš´ìŠ¤íŠ¸ë¦¬ë° íƒœìŠ¤í¬ë¥¼ í’€ê¸° ìœ„í•´ ì‚¬ìš©ë˜ë¯€ë¡œ ëŒ€í‘œì ì¸ transfer learning ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜ ì–¸ì–´í•™ìŠµì´ë¼ëŠ” ë„ë©”ì¸ ë‚´ì—ì„œ 90%ì˜ ì‚¬ì „í•™ìŠµì— í™œìš©ë˜ëŠ” ë°©ëŒ€í•œ ì–‘ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ì–´ëª¨ë¸ì„ í†µí•´ ì„ë² ë”©í•œ í›„ (feat. Google)  ë™ì¼ ì–¸ì–´ ëª¨ë¸(bert ë“±ë“±) ì—ì„œ ì‡¼ê·œëª¨ ë°ì´í„° (10%) ë¡œclassification ë“±ë“±ì˜ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤í¬ë¥¼ í’€ê¸°ë„ í•¨ìœ¼ë¡œ fine-tuning ì´ë¼ê³  í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. 

ì œê°€ ì´í•´í•œ ë°”ì— ë”°ë¥´ë©´ ì–´ì¨Œë“  ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ ì‚¬ì „í•™ìŠµê³¼ì œë¥¼ í†µí•´ ì–¸ì–´ëª¨ë¸ì—ì„œ ì„ë² ë”©ì„ ì‹œí‚¤ëŠ”ë° ì„ë² ë”©ì‹œí‚¨ ì–¸ì–´ëª¨ë¸ì—ì„œ ì†Œê·œëª¨ ë°ì´í„°ë¡œ ê³¼ì œí•™ìŠµì„ í•˜ë©´ fine-tuning, ì–¸ì–´ëª¨ë¸ ì„ë² ë”©ë§Œ ê°€ì ¸ì™€ì„œ ë‹¤ë¥¸ ëª¨ë¸ì— ì ì‘ì‹œí‚¤ë©´ transfer learning ì´ ì•„ë‹ê¹Œ ìƒê°í•©ë‹ˆë‹¤. 

ë”°ë¼ì„œ ì´ì œê¹Œì§€ëŠ” ì„ë² ë”© ê³¼ì œ / ì„ë² ë”©ì„ í†µí•œ down-streaming ê³¼ì œê°€ ë¶„ë¦¬ ë˜ì—ˆìŠµë‹ˆë‹¤. ì„ë² ë”©ì„ ì˜í•´ë†“ì•„ë„ í’€ê³ ìí•˜ëŠ” ê³¼ì œì— ì¼ì¼ì´ fine-tuning í•´ì•¼ë˜ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. 

**í•´ë‹¹ ë¬¸ì œê°€ ìƒê¸´ ì›ì¸ì€ nlp ì—ì„œ í’€ê³ ìí•˜ëŠ” ê³¼ì œì— ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ê°€ ê³¼ì œ ì¢…ë¥˜ì— ë”°ë¼ì„œ ë‹¤ì–‘í•œ ë¼ë²¨ê°’ì„ ê°€ì§€ëŠ” labelled data ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.** pretrained ëœ bert ë¥¼ ì‚¬ìš©í•´ì„œ ê°ì„±ë¶„ì„ì„ í•˜ê³  ì‹¶ë‹¤ë©´ ì •ë‹µ ê°’ì€ 0,1ì¸ë° ë°˜í•´ ê°œì²´ëª… ì¸ì‹ ì •ë‹µ ê°’ì€ PERSON,FIELD ë“±ë“±ì…ë‹ˆë‹¤. 

í•œí¸ Pre-training ê³¼ì œì—ì„œëŠ” ëª¨ë¸ì´ ì–¸ì–´ëŠ¥ë ¥ì„ ê°–ê²Œ í•˜ê¸° ìœ„í•´ì„œ (ê·¸ë˜ì„œ ì œëŒ€ë¡œ ì„ë² ë”©í•˜ë„ë¡ í•˜ê¸° ìœ„í•´ì„œ) ë¬¸ì¥ ë‚´ íŠ¹ì • ë‹¨ì–´ì— ë§ˆìŠ¤í¬ë¥¼ ëš«ì–´ë†“ê³  í•´ë‹¹ ë‹¨ì–´ë¥¼ ë§ì¶”ê²Œ í•˜ê¸°ë„ í•˜ê³ ,ë‹¨ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ë‚˜ì—´í•´ê°€ë©´ì„œ ë¬¸ì¥ ë‚´ ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ ë§ì¶”ê²Œ í•˜ê¸°ë„ í•©ë‹ˆë‹¤. ì¦‰ íŠ¹ì • task ì— fine-tuning í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ text ë¥¼ ì…ë ¥ìœ¼ë¡œ í•˜ë©´ ì–´ë– í•œ text ë¥¼ ë‚´ë±‰ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤. 

**ê·¸ë˜ì„œ t5ì—ì„œëŠ” ê° downstream task ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ë¥¼ text to text í˜•ì‹ìœ¼ë¡œ ë°”ê¾¸ë©´ ì¼ì¼ì´ ê³¼ì œì— ë”°ë¼ì„œ ë‹¤ë¥´ê²Œ fine-tuning í•  í•„ìš”ê°€ ì—†ì§€ ì•Šì„ê¹Œ ì•„ì´ë””ì–´ë¥¼ ë‚¸ ê²ƒì…ë‹ˆë‹¤ ! (ë°œìƒì˜ ì „í™˜)**

ëª¨ë“  downstream task ë°ì´í„°ëŠ” pre-train í•œ ëª¨ë¸ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œë” text to text í˜•ì‹ìœ¼ë¡œ ì§‘ì–´ë„£ì–´ì§‘ë‹ˆë‹¤. ê³¼ì œê°€ 5ê°œë¼ê³  ì¹˜ë©´ ì´ì œ ê° ê³¼ì œì— ë§ëŠ” ëª¨ë¸ 5ê°œë¥¼ ëª¨ë‘ ë§Œë“¤ì–´ì¤„ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹  ëª¨ë“  5ê°œì˜ ê³¼ì œì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ë¥¼ text to text í˜•ì‹ìœ¼ë¡œ pre-train í•œ ëª¨ë¸(=Transfer Transforemr) ì— ì§‘ì–´ë„£ìŠµë‹ˆë‹¤.

ê·¸ëŸ¬ë©´, **ê·¸ë˜ë„ ë°ì´í„° í˜•ì‹ë§Œ text to text ë¡œ ê°™ê³  ê³¼ì œì˜ ì„±ê²©ì€ ë‹¤ë¥¸ë° ê·¸ê²Œ ê°€ëŠ¥í• ê¹Œ ?** ë¼ëŠ” ì˜ë¬¸ì´ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ê·¸ë˜ì„œ input_text ë§¨ ì•ì— ì–´ë– í•œ ê³¼ì œì¸ì§€ë¥¼ ëª…ì‹œí•´ì¤ë‹ˆë‹¤. 

![ìŠ¤í¬ë¦°ìƒ· 2021-02-11 ì˜¤í›„ 1 14 41](https://user-images.githubusercontent.com/67775336/107601982-8e527080-6c6b-11eb-9b99-312bce0abfbc.png)

ê·¸ëŸ¬ë©´ pretrain ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê³¼ì œë„ ë§¤ìš° ë‹¤ì–‘í•œë° ê·¸ ì¤‘ ì–´ë–¤ ê²ƒì„ ì‚¬ìš©í• ì§€ë„ ì •ë§ ë§ì€ ì‹¤í—˜ì„ í•´ì£¼ì—ˆìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ corrupting spans ê°€ ì œì¼ íš¨ê³¼ì ì´ì–´ì„œ ì´ë¥¼ í™œìš©í–ˆë‹¤ê³  í•©ë‹ˆë‹¤. 

![ìŠ¤í¬ë¦°ìƒ· 2021-02-11 ì˜¤í›„ 1 35 40](https://user-images.githubusercontent.com/67775336/107602862-484adc00-6c6e-11eb-84e5-c92c7aeebb6d.png)

### 2. C4 ë°ì´í„° ì…‹

ê·¸ëŸ¬ë©´ pre-train ì— í•™ìŠµí•  ë°ì´í„°ëŠ” ë¬´ì—‡ì„ ì¼ëŠ”ì§€ë„ ë§¤ìš° ì¤‘ìš”í•  ê²ƒì…ë‹ˆë‹¤. í•´ë‹¹ ë¶€ë¶„ë„ T5ì˜ ë‘ë“œëŸ¬ì§„ ì¥ì ì„ ê°€ì ¸ë‹¤ ì¤€ í•µì‹¬ì´ë¼ê³  ì—¬ê²¨ì§‘ë‹ˆë‹¤. 

Common Crawl ì€ ë§¤ë‹¬ ê°ì¢… ì›¹í˜ì´ì§€ì—ì„œ 20TB ì˜ ë°ì´í„° ì…‹ì„ ê¸ì–´ì„œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤. ë§¤ìš° ë°©ëŒ€í•˜ê³  ì •ì œë˜ì–´ìˆì§€ ì•Šì€ unlabelled ë°ì´í„° ì…‹ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ì €ëŠ” ì»´í“¨í„°ì— ëŒ€í•´ì„œ ì•„ì§ ì˜ ëª°ë¼ì„œ ì‚¬ì‹¤ mb,gb,tb ì´ëŸ° ì‹ìœ¼ë¡œ ë§í•˜ë©´ ê°ì„ ì˜ ì¡ì§€ ëª»í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ì¢€ ë” ê°€ëŠ ì„ í•´ë³´ê¸° ìœ„í•´ì„œ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. 

ì»´í“¨í„°ëŠ” 0 í•˜ê³  1 ë§Œì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 1ë¹„íŠ¸ ë‹¨ìœ„ë¡œ ì´ë¥¼ í‘œí˜„í•©ë‹ˆë‹¤.

8ë¹„íŠ¸ê°€ ëª¨ì´ë©´ 1ë°”ì´íŠ¸ê°€ ë©ë‹ˆë‹¤. ì¦‰ 8ìë¦¬ì˜ ê³µê°„ ê°ê°ì— 1 ë˜ëŠ” 0ì„ ë„£ì„ ìˆ˜ ìˆëŠ” ì–‘ì…ë‹ˆë‹¤. 

1gbëŠ” 1000^3 ë°”ì´íŠ¸ì…ë‹ˆë‹¤. 

1tbëŠ” 1000 gb ì…ë‹ˆë‹¤. 

ë„µ ê·¸ëŸ¬ë‹ˆê¹Œ ë§¤ë‹¬ 20TB ì´ë¼ê³  í•˜ë©´ ëŒ€ì¶© ê°€ëŠ ë§Œ í•´ë„ ì–´ë§ˆì–´ë§ˆí•œ ì–‘ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 

**C4 ëŠ” ì´ë¥¼ ë§¤ìš° ì„¬ì„¸í•˜ê²Œ ì •ì œí•œ ë°ì´í„° ì…‹ì…ë‹ˆë‹¤.** 

ì–´ë–»ê²Œ ì •ì œí–ˆëŠ”ì§€ì— ëŒ€í•´ì„œëŠ” ì´ì™€ ê°™ì´ ì„¤ëª…ë˜ì–´ìˆì—ˆìŠµë‹ˆë‹¤. ì‚¬ì‹¤ ìƒì‹ì ìœ¼ë¡œëŠ” íŠ¹ë³„í•œê²Œ ì—†ëŠ” ë‚´ìš©ì¸ ê²ƒ ê°™ì€ë° ì´ ë°©ëŒ€í•œ ì–‘ì˜ ë°ì´í„°ë¥¼ ì´ë ‡ê²Œ ê¹”ë”í•˜ê²Œ ì •ì œí–ˆë‹¤ëŠ”ê²Œ í¬ì¸íŠ¸ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 

1. Retaining sentences that end only with a valid terminal punctuation mark (a period, exclamation mark, question mark, or end quotation mark).
2. Removing any page containing offensive words that appear on the â€œ[List of Dirty, Naughty, Obscene or Otherwise Bad Words](https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words)â€.
3. â€œJavaScript must be enabledâ€ type warnings are removed by filtering out any line that contains the word JavaScript.
4. Pages with placeholder text like â€œlorem ipsumâ€ are removed.
5. Source codes are removed by removing any pages that contain a curly brace â€œ{â€ (since curly braces appear in many well-known programming languages).
6. For removing duplicates, three-sentence spans are considered. Any duplicate occurrences of the same 3 sentences are filtered out.
7. Finally, since the downstream tasks are mostly for English language, [langdetect](https://pypi.org/project/langdetect/) is used to filter out any pages that are not classified as English with a probability of at least 0.99.

**This resulted in a 750GB dataset** which is not just reasonably larger than the most pre-training datasets but also contains a relatively very clean text.

[T5:Text-To-Text Transfer Transformer](https://towardsdatascience.com/t5-text-to-text-transfer-transformer-643f89e8905e )

### 3. mT5 , mc4

mc4 ëŠ” ì œê°€ í•´ë‹¹ ë…¼ë¬¸ì„ ì‚´í´ë³´ê²Œ ëœ ê³„ê¸°ì´ê¸°ë„ í•©ë‹ˆë‹¤. êµ¬ê¸€ì€ c4ë¥¼ ë§Œë“¤ê³  t5ë¥¼ í•™ìŠµì‹œí‚¤ëŠ”ë° ê·¸ì¹˜ì§€ ì•Šê³  multilingual model ê¹Œì§€ë„ í•´ë‹¹ ëª¨ë¸ì„ í™•ì¥í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤. ğŸŒ

The mT5 is a multilingual variant of Googleâ€™s T5 model that was pre-trained over a dataset of more than 101 languages and contains between 300 million and 13 billion parameters. While explicitly-designed C4 dataset for English only, mC4 includes 107 languages along with 10,000 and more web pages over 71 monthly scrapes till date.

[What is mT5?](https://www.analyticssteps.com/blogs/what-mt5-google-ai-open-source-multilingual-model-trained-over-101-languages )

ì‹¤ì œ ì½”ë“œ í•™ìŠµí•  ë•Œ mc4ë¡œ í•™ìŠµí•œ mT5 ë¥¼ í™œìš©í•˜ê¸° ìœ„í•´ì„œ hugging face íŠœí† ë¦¬ì–¼ ì‚¬ì´íŠ¸ì— ë“¤ì–´ê°€ë³´ë‹ˆê¹Œ t5 íŠœí† ë¦¬ì–¼ì—ì„œ ì„ íƒ ì˜µì…˜ë§Œ mt5ë¡œ ì£¼ë©´ ì‚¬ìš©ì´ ê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤. 

### 4. ì•„í‚¤í…ì²˜ ìì²´ê°€ íŠ¸ëœìŠ¤í¬ë¨¸ì™€ ë‹¤ë¥¸ ë¶€ë¶„

T5 ëŠ” ëª…ë°±í•œ íŠ¸ëœìŠ¤í¬ë¨¸ê³„ ëª¨ë¸ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì•„í‚¤í…ì²˜ ìì²´ê°€ íŠ¸ëœìŠ¤í¬ë¨¸ì™€ ì™„ì „íˆ ë˜‘ê°™ì§€ëŠ” ì•Šì€ë° ë°”ë¡œ **relative position encoding** ë¶€ë¶„ì´ ë‹¤ë¦…ë‹ˆë‹¤. ê° í† í°ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” position encoding ê°’ì„ relative (ë‹¤ë¥¸ í† í°ë“¤ê³¼ì˜ ìœ„ì¹˜ê´€ê³„ë¥¼ ê³ ë ¤í•˜ì—¬ì„œ) í•˜ê²Œ ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤. ìŠ¤ì¹¼ë¼ ê°’ì´ë¯€ë¡œ ì–´í…ì…˜ê¹Œì§€ ë‹¤ ê±°ì¹œ í›„ ë‚˜ì˜¨ ìŠ¤ì¹¼ë¼ê°’ì—ë‹¤ ë”í•´ì¤ë‹ˆë‹¤.  ë”°ë¼ì„œ ì„ë² ë”©í•  ë•Œ ìœ„ì¹˜ ì •ë³´ë¥¼ ì£¼ëŠ” í˜•íƒœë¡œ ë“¤ì–´ê°€ì§€ ì•Šê³  ì–´í…ì…˜ ìˆ˜í–‰ í›„ ë”í•´ì£¼ëŠ” ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤. 

í•´ë‹¹ ë‚´ìš© ê³µë¶€ëŠ” [T5-relative position encoding](https://soundprovider.tistory.com/entry/Exploring-Transfer-Learning-with-T5-the-Text-To-Text-Transfer-Transformer-2) ì—¬ê¸° ë¸”ë¡œê·¸ì—ì„œ í° ë„ì›€ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ğŸ™‡ğŸ»â€â™€ï¸

### 5. mt5 ê°„ë‹¨í•œ ì½”ë“œ êµ¬í˜„

tqdm ì—ëŸ¬ê°€ ê³„ì† ë– ì„œ ì´ìŠˆ í˜ì´ì§€ë¥¼ ë³¸ í›„ ë²„ì „ì„ 4.47.0 ìœ¼ë¡œ ì¡°ì •í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.

ë°ì´í„° ì…‹ì€ ìºê¸€ì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. 

training data - [HindiEnglish Corpora](https://www.kaggle.com/aiswaryaramachandran/hindienglish-corpora)

evaluation data - [Hindi English Sentence Pairs](https://www.kaggle.com/kkhandekar/hindi-english-sentence-pairs)

íŠœí† ë¦¬ì–¼ì´ hugging face ì— ì˜ ë‚˜ì™€ìˆìŠµë‹ˆë‹¤. 

[T5 Model](https://simpletransformers.ai/docs/t5-model/)

ì‚¬ì‹¤ ì½”ë©ì—ì„œ ëŒë¦¬ë‹ˆê¹Œ í™˜ê²½ì´ ì•ˆ ë°›ì³ì¤˜ì„œ ë§ì€ ì–´ë ¤ì›€ì„ ê²ªì—ˆìŠµë‹ˆë‹¤. ì œëŒ€ë¡œ ëŒë¦¬ë ¤ë©´ gpuê°€ ìˆì–´ì•¼í•  ë“¯ í•©ë‹ˆë‹¤. 

```python
!pip install tqdm==4.47.0
!pip install simpletransformers
```


```python
import os
import pandas as pd
import logging
import pandas as pd
import simpletransformers.t5 
```


```python
from simpletransformers.t5 import T5Model, T5Args
```


```python
eval_data=pd.read_csv('hindeng.csv',encoding='utf-8',header=None)
eval_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Wow!</td>
      <td>à¤µà¤¾à¤¹!</td>
      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Help!</td>
      <td>à¤¬à¤šà¤¾à¤“!</td>
      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jump.</td>
      <td>à¤‰à¤›à¤²à¥‹.</td>
      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Jump.</td>
      <td>à¤•à¥‚à¤¦à¥‹.</td>
      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Jump.</td>
      <td>à¤›à¤²à¤¾à¤‚à¤—.</td>
      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>
    </tr>
  </tbody>
</table>
</div>




```python
hind_eval=eval_data[1].astype(str)
eng_eval=eval_data[0].astype(str)
```


```python
eval_transform=[]
for hindi,english in zip(hind_eval,eng_eval):
    eval_transform.append(["translate hindi to english",hindi,english])
    eval_transform.append(["translate english to hindi",english,hindi])
```


```python
final_data_eval=pd.DataFrame(eval_transform,columns=["prefix","input_text","target_text"])
```


```python
final_data_eval
```



<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prefix</th>
      <th>input_text</th>
      <th>target_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>translate hindi to english</td>
      <td>à¤µà¤¾à¤¹!</td>
      <td>Wow!</td>
    </tr>
    <tr>
      <th>1</th>
      <td>translate english to hindi</td>
      <td>Wow!</td>
      <td>à¤µà¤¾à¤¹!</td>
    </tr>
    <tr>
      <th>2</th>
      <td>translate hindi to english</td>
      <td>à¤¬à¤šà¤¾à¤“!</td>
      <td>Help!</td>
    </tr>
    <tr>
      <th>3</th>
      <td>translate english to hindi</td>
      <td>Help!</td>
      <td>à¤¬à¤šà¤¾à¤“!</td>
    </tr>
    <tr>
      <th>4</th>
      <td>translate hindi to english</td>
      <td>à¤‰à¤›à¤²à¥‹.</td>
      <td>Jump.</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5543</th>
      <td>translate english to hindi</td>
      <td>Democracy is the worst form of government, exc...</td>
      <td>à¤²à¥‹à¤•à¤¤à¤‚à¤¤à¥à¤° à¤¸à¤°à¤•à¤¾à¤° à¤•à¤¾ à¤¸à¤¬à¤¸à¥‡ à¤˜à¤¿à¤¨à¥Œà¤¨à¤¾ à¤°à¥‚à¤ª à¤¹à¥ˆ, à¤…à¤—à¤° à¤¬à¤¾à¤•à¥€...</td>
    </tr>
    <tr>
      <th>5544</th>
      <td>translate hindi to english</td>
      <td>à¤…à¤—à¤° à¤®à¥‡à¤°à¤¾ à¤¬à¥‡à¤Ÿà¤¾ à¤Ÿà¥à¤°à¥‡à¤«à¤¼à¤¿à¤• à¤¹à¤¾à¤¦à¤¸à¥‡ à¤®à¥‡à¤‚ à¤¨à¤¹à¥€à¤‚ à¤®à¤¾à¤°à¤¾ à¤—à¤¯à¤¾...</td>
      <td>If my boy had not been killed in the traffic a...</td>
    </tr>
    <tr>
      <th>5545</th>
      <td>translate english to hindi</td>
      <td>If my boy had not been killed in the traffic a...</td>
      <td>à¤…à¤—à¤° à¤®à¥‡à¤°à¤¾ à¤¬à¥‡à¤Ÿà¤¾ à¤Ÿà¥à¤°à¥‡à¤«à¤¼à¤¿à¤• à¤¹à¤¾à¤¦à¤¸à¥‡ à¤®à¥‡à¤‚ à¤¨à¤¹à¥€à¤‚ à¤®à¤¾à¤°à¤¾ à¤—à¤¯à¤¾...</td>
    </tr>
    <tr>
      <th>5546</th>
      <td>translate hindi to english</td>
      <td>à¤œà¤¬ à¤®à¥ˆà¤‚ à¤¬à¤šà¥à¤šà¤¾ à¤¥à¤¾, à¤®à¥à¤à¥‡ à¤•à¥€à¤¡à¤¼à¥‹à¤‚ à¤•à¥‹ à¤›à¥‚à¤¨à¥‡ à¤¸à¥‡ à¤•à¥‹à¤ˆ à¤ªà¤°...</td>
      <td>When I was a kid, touching bugs didn't bother ...</td>
    </tr>
    <tr>
      <th>5547</th>
      <td>translate english to hindi</td>
      <td>When I was a kid, touching bugs didn't bother ...</td>
      <td>à¤œà¤¬ à¤®à¥ˆà¤‚ à¤¬à¤šà¥à¤šà¤¾ à¤¥à¤¾, à¤®à¥à¤à¥‡ à¤•à¥€à¤¡à¤¼à¥‹à¤‚ à¤•à¥‹ à¤›à¥‚à¤¨à¥‡ à¤¸à¥‡ à¤•à¥‹à¤ˆ à¤ªà¤°...</td>
    </tr>
  </tbody>
</table>
<p>5548 rows Ã— 3 columns</p>
</div>




```python
final_data_eval.to_csv("final_data_eval.csv")
```


```python
data=pd.read_csv('mt5_test.csv')
data.head()
```



<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>source</th>
      <th>english_sentence</th>
      <th>hindi_sentence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ted</td>
      <td>politicians do not have permission to do what ...</td>
      <td>à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤œà¥à¤à¥‹à¤‚ à¤•à¥‡ à¤ªà¤¾à¤¸ à¤œà¥‹ à¤•à¤¾à¤°à¥à¤¯ à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¤¿à¤, à¤µà¤¹ à¤•à¤°...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ted</td>
      <td>I'd like to tell you about one such child,</td>
      <td>à¤®à¤ˆ à¤†à¤ªà¤•à¥‹ à¤à¤¸à¥‡ à¤¹à¥€ à¤à¤• à¤¬à¤šà¥à¤šà¥‡ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¬à¤¤à¤¾à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>indic2012</td>
      <td>This percentage is even greater than the perce...</td>
      <td>à¤¯à¤¹ à¤ªà¥à¤°à¤¤à¤¿à¤¶à¤¤ à¤­à¤¾à¤°à¤¤ à¤®à¥‡à¤‚ à¤¹à¤¿à¤¨à¥à¤¦à¥à¤“à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤¶à¤¤ à¤¸à¥‡ à¤…à¤§à¤¿à¤• à¤¹à¥ˆà¥¤</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ted</td>
      <td>what we really mean is that they're bad at not...</td>
      <td>à¤¹à¤® à¤¯à¥‡ à¤¨à¤¹à¥€à¤‚ à¤•à¤¹à¤¨à¤¾ à¤šà¤¾à¤¹à¤¤à¥‡ à¤•à¤¿ à¤µà¥‹ à¤§à¥à¤¯à¤¾à¤¨ à¤¨à¤¹à¥€à¤‚ à¤¦à¥‡ à¤ªà¤¾à¤¤à¥‡</td>
    </tr>
    <tr>
      <th>4</th>
      <td>indic2012</td>
      <td>.The ending portion of these Vedas is called U...</td>
      <td>à¤‡à¤¨à¥à¤¹à¥€à¤‚ à¤µà¥‡à¤¦à¥‹à¤‚ à¤•à¤¾ à¤…à¤‚à¤¤à¤¿à¤® à¤­à¤¾à¤— à¤‰à¤ªà¤¨à¤¿à¤·à¤¦ à¤•à¤¹à¤²à¤¾à¤¤à¤¾ à¤¹à¥ˆà¥¤</td>
    </tr>
  </tbody>
</table>



```python
english_sentence=data['english_sentence'].astype(str)
hindi_sentence=data['hindi_sentence'].astype(str)
```


```python
data_transform=[]
for hindi,english in zip(hindi_sentence,english_sentence):
    data_transform.append(["translate hindi to english",hindi,english])
    data_transform.append(["translate english to hindi",english,hindi])
```


```python
final_data=pd.DataFrame(data_transform,columns=["prefix","input_text","target_text"])
```


```python
final_data
```



<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prefix</th>
      <th>input_text</th>
      <th>target_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>translate hindi to english</td>
      <td>à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤œà¥à¤à¥‹à¤‚ à¤•à¥‡ à¤ªà¤¾à¤¸ à¤œà¥‹ à¤•à¤¾à¤°à¥à¤¯ à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¤¿à¤, à¤µà¤¹ à¤•à¤°...</td>
      <td>politicians do not have permission to do what ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>translate english to hindi</td>
      <td>politicians do not have permission to do what ...</td>
      <td>à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤œà¥à¤à¥‹à¤‚ à¤•à¥‡ à¤ªà¤¾à¤¸ à¤œà¥‹ à¤•à¤¾à¤°à¥à¤¯ à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¤¿à¤, à¤µà¤¹ à¤•à¤°...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>translate hindi to english</td>
      <td>à¤®à¤ˆ à¤†à¤ªà¤•à¥‹ à¤à¤¸à¥‡ à¤¹à¥€ à¤à¤• à¤¬à¤šà¥à¤šà¥‡ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¬à¤¤à¤¾à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚...</td>
      <td>I'd like to tell you about one such child,</td>
    </tr>
    <tr>
      <th>3</th>
      <td>translate english to hindi</td>
      <td>I'd like to tell you about one such child,</td>
      <td>à¤®à¤ˆ à¤†à¤ªà¤•à¥‹ à¤à¤¸à¥‡ à¤¹à¥€ à¤à¤• à¤¬à¤šà¥à¤šà¥‡ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¬à¤¤à¤¾à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>translate hindi to english</td>
      <td>à¤¯à¤¹ à¤ªà¥à¤°à¤¤à¤¿à¤¶à¤¤ à¤­à¤¾à¤°à¤¤ à¤®à¥‡à¤‚ à¤¹à¤¿à¤¨à¥à¤¦à¥à¤“à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤¶à¤¤ à¤¸à¥‡ à¤…à¤§à¤¿à¤• à¤¹à¥ˆà¥¤</td>
      <td>This percentage is even greater than the perce...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>255209</th>
      <td>translate english to hindi</td>
      <td>As for the other derivatives of sulphur , the ...</td>
      <td>à¤œà¤¹à¤¾à¤‚ à¤¤à¤• à¤—à¤‚à¤§à¤• à¤•à¥‡ à¤…à¤¨à¥à¤¯ à¤‰à¤¤à¥à¤ªà¤¾à¤¦à¥‹à¤‚ à¤•à¤¾ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¹à¥ˆ , à¤¦...</td>
    </tr>
    <tr>
      <th>255210</th>
      <td>translate hindi to english</td>
      <td>Zà¤°à¤šà¤¨à¤¾-à¤ªà¥à¤°à¤•à¤¿à¤¯à¤¾ à¤•à¥‹ à¤‰à¤¸à¤¨à¥‡ à¤à¤• à¤ªà¤¹à¥‡à¤²à¥€ à¤®à¥‡à¤‚ à¤¯à¥‹à¤‚ à¤¬à¤¾à¤‚à¤§à¤¾ à¤¹à¥ˆ .</td>
      <td>its complicated functioning is defined thus in...</td>
    </tr>
    <tr>
      <th>255211</th>
      <td>translate english to hindi</td>
      <td>its complicated functioning is defined thus in...</td>
      <td>Zà¤°à¤šà¤¨à¤¾-à¤ªà¥à¤°à¤•à¤¿à¤¯à¤¾ à¤•à¥‹ à¤‰à¤¸à¤¨à¥‡ à¤à¤• à¤ªà¤¹à¥‡à¤²à¥€ à¤®à¥‡à¤‚ à¤¯à¥‹à¤‚ à¤¬à¤¾à¤‚à¤§à¤¾ à¤¹à¥ˆ .</td>
    </tr>
    <tr>
      <th>255212</th>
      <td>translate hindi to english</td>
      <td>à¤¹à¤¾à¤² à¤¹à¥€ à¤®à¥‡à¤‚ à¤‰à¤¨à¥à¤¹à¥‡à¤‚ à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤ à¥‡à¤•à¤¾ à¤®à¤¿à¤²à¤¾ à¤¹à¥ˆ à¤•à¤°à¥€à¤¬ à¤¸à¥Œ ...</td>
      <td>They've just won four government contracts to ...</td>
    </tr>
    <tr>
      <th>255213</th>
      <td>translate english to hindi</td>
      <td>They've just won four government contracts to ...</td>
      <td>à¤¹à¤¾à¤² à¤¹à¥€ à¤®à¥‡à¤‚ à¤‰à¤¨à¥à¤¹à¥‡à¤‚ à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤ à¥‡à¤•à¤¾ à¤®à¤¿à¤²à¤¾ à¤¹à¥ˆ à¤•à¤°à¥€à¤¬ à¤¸à¥Œ ...</td>
    </tr>
  </tbody>
</table>
<p>255214 rows Ã— 3 columns</p>

```python
final_data.to_csv("final_data_train.csv")
```


```python
train_df=pd.read_csv("final_data_train.csv").astype(str)
```


```python
eval_df=pd.read_csv("final_data_eval.csv").astype(str)
```


```python
del train_df["Unnamed: 0"]
del eval_df["Unnamed: 0"]
```


```python
train_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prefix</th>
      <th>input_text</th>
      <th>target_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>translate hindi to english</td>
      <td>à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤œà¥à¤à¥‹à¤‚ à¤•à¥‡ à¤ªà¤¾à¤¸ à¤œà¥‹ à¤•à¤¾à¤°à¥à¤¯ à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¤¿à¤, à¤µà¤¹ à¤•à¤°...</td>
      <td>politicians do not have permission to do what ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>translate english to hindi</td>
      <td>politicians do not have permission to do what ...</td>
      <td>à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤œà¥à¤à¥‹à¤‚ à¤•à¥‡ à¤ªà¤¾à¤¸ à¤œà¥‹ à¤•à¤¾à¤°à¥à¤¯ à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¤¿à¤, à¤µà¤¹ à¤•à¤°...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>translate hindi to english</td>
      <td>à¤®à¤ˆ à¤†à¤ªà¤•à¥‹ à¤à¤¸à¥‡ à¤¹à¥€ à¤à¤• à¤¬à¤šà¥à¤šà¥‡ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¬à¤¤à¤¾à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚...</td>
      <td>I'd like to tell you about one such child,</td>
    </tr>
    <tr>
      <th>3</th>
      <td>translate english to hindi</td>
      <td>I'd like to tell you about one such child,</td>
      <td>à¤®à¤ˆ à¤†à¤ªà¤•à¥‹ à¤à¤¸à¥‡ à¤¹à¥€ à¤à¤• à¤¬à¤šà¥à¤šà¥‡ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¬à¤¤à¤¾à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>translate hindi to english</td>
      <td>à¤¯à¤¹ à¤ªà¥à¤°à¤¤à¤¿à¤¶à¤¤ à¤­à¤¾à¤°à¤¤ à¤®à¥‡à¤‚ à¤¹à¤¿à¤¨à¥à¤¦à¥à¤“à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤¶à¤¤ à¤¸à¥‡ à¤…à¤§à¤¿à¤• à¤¹à¥ˆà¥¤</td>
      <td>This percentage is even greater than the perce...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>255209</th>
      <td>translate english to hindi</td>
      <td>As for the other derivatives of sulphur , the ...</td>
      <td>à¤œà¤¹à¤¾à¤‚ à¤¤à¤• à¤—à¤‚à¤§à¤• à¤•à¥‡ à¤…à¤¨à¥à¤¯ à¤‰à¤¤à¥à¤ªà¤¾à¤¦à¥‹à¤‚ à¤•à¤¾ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¹à¥ˆ , à¤¦...</td>
    </tr>
    <tr>
      <th>255210</th>
      <td>translate hindi to english</td>
      <td>Zà¤°à¤šà¤¨à¤¾-à¤ªà¥à¤°à¤•à¤¿à¤¯à¤¾ à¤•à¥‹ à¤‰à¤¸à¤¨à¥‡ à¤à¤• à¤ªà¤¹à¥‡à¤²à¥€ à¤®à¥‡à¤‚ à¤¯à¥‹à¤‚ à¤¬à¤¾à¤‚à¤§à¤¾ à¤¹à¥ˆ .</td>
      <td>its complicated functioning is defined thus in...</td>
    </tr>
    <tr>
      <th>255211</th>
      <td>translate english to hindi</td>
      <td>its complicated functioning is defined thus in...</td>
      <td>Zà¤°à¤šà¤¨à¤¾-à¤ªà¥à¤°à¤•à¤¿à¤¯à¤¾ à¤•à¥‹ à¤‰à¤¸à¤¨à¥‡ à¤à¤• à¤ªà¤¹à¥‡à¤²à¥€ à¤®à¥‡à¤‚ à¤¯à¥‹à¤‚ à¤¬à¤¾à¤‚à¤§à¤¾ à¤¹à¥ˆ .</td>
    </tr>
    <tr>
      <th>255212</th>
      <td>translate hindi to english</td>
      <td>à¤¹à¤¾à¤² à¤¹à¥€ à¤®à¥‡à¤‚ à¤‰à¤¨à¥à¤¹à¥‡à¤‚ à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤ à¥‡à¤•à¤¾ à¤®à¤¿à¤²à¤¾ à¤¹à¥ˆ à¤•à¤°à¥€à¤¬ à¤¸à¥Œ ...</td>
      <td>They've just won four government contracts to ...</td>
    </tr>
    <tr>
      <th>255213</th>
      <td>translate english to hindi</td>
      <td>They've just won four government contracts to ...</td>
      <td>à¤¹à¤¾à¤² à¤¹à¥€ à¤®à¥‡à¤‚ à¤‰à¤¨à¥à¤¹à¥‡à¤‚ à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤ à¥‡à¤•à¤¾ à¤®à¤¿à¤²à¤¾ à¤¹à¥ˆ à¤•à¤°à¥€à¤¬ à¤¸à¥Œ ...</td>
    </tr>
  </tbody>
</table>
<p>255214 rows Ã— 3 columns</p>



```python
eval_df
```



<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prefix</th>
      <th>input_text</th>
      <th>target_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>translate hindi to english</td>
      <td>à¤µà¤¾à¤¹!</td>
      <td>Wow!</td>
    </tr>
    <tr>
      <th>1</th>
      <td>translate english to hindi</td>
      <td>Wow!</td>
      <td>à¤µà¤¾à¤¹!</td>
    </tr>
    <tr>
      <th>2</th>
      <td>translate hindi to english</td>
      <td>à¤¬à¤šà¤¾à¤“!</td>
      <td>Help!</td>
    </tr>
    <tr>
      <th>3</th>
      <td>translate english to hindi</td>
      <td>Help!</td>
      <td>à¤¬à¤šà¤¾à¤“!</td>
    </tr>
    <tr>
      <th>4</th>
      <td>translate hindi to english</td>
      <td>à¤‰à¤›à¤²à¥‹.</td>
      <td>Jump.</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5543</th>
      <td>translate english to hindi</td>
      <td>Democracy is the worst form of government, exc...</td>
      <td>à¤²à¥‹à¤•à¤¤à¤‚à¤¤à¥à¤° à¤¸à¤°à¤•à¤¾à¤° à¤•à¤¾ à¤¸à¤¬à¤¸à¥‡ à¤˜à¤¿à¤¨à¥Œà¤¨à¤¾ à¤°à¥‚à¤ª à¤¹à¥ˆ, à¤…à¤—à¤° à¤¬à¤¾à¤•à¥€...</td>
    </tr>
    <tr>
      <th>5544</th>
      <td>translate hindi to english</td>
      <td>à¤…à¤—à¤° à¤®à¥‡à¤°à¤¾ à¤¬à¥‡à¤Ÿà¤¾ à¤Ÿà¥à¤°à¥‡à¤«à¤¼à¤¿à¤• à¤¹à¤¾à¤¦à¤¸à¥‡ à¤®à¥‡à¤‚ à¤¨à¤¹à¥€à¤‚ à¤®à¤¾à¤°à¤¾ à¤—à¤¯à¤¾...</td>
      <td>If my boy had not been killed in the traffic a...</td>
    </tr>
    <tr>
      <th>5545</th>
      <td>translate english to hindi</td>
      <td>If my boy had not been killed in the traffic a...</td>
      <td>à¤…à¤—à¤° à¤®à¥‡à¤°à¤¾ à¤¬à¥‡à¤Ÿà¤¾ à¤Ÿà¥à¤°à¥‡à¤«à¤¼à¤¿à¤• à¤¹à¤¾à¤¦à¤¸à¥‡ à¤®à¥‡à¤‚ à¤¨à¤¹à¥€à¤‚ à¤®à¤¾à¤°à¤¾ à¤—à¤¯à¤¾...</td>
    </tr>
    <tr>
      <th>5546</th>
      <td>translate hindi to english</td>
      <td>à¤œà¤¬ à¤®à¥ˆà¤‚ à¤¬à¤šà¥à¤šà¤¾ à¤¥à¤¾, à¤®à¥à¤à¥‡ à¤•à¥€à¤¡à¤¼à¥‹à¤‚ à¤•à¥‹ à¤›à¥‚à¤¨à¥‡ à¤¸à¥‡ à¤•à¥‹à¤ˆ à¤ªà¤°...</td>
      <td>When I was a kid, touching bugs didn't bother ...</td>
    </tr>
    <tr>
      <th>5547</th>
      <td>translate english to hindi</td>
      <td>When I was a kid, touching bugs didn't bother ...</td>
      <td>à¤œà¤¬ à¤®à¥ˆà¤‚ à¤¬à¤šà¥à¤šà¤¾ à¤¥à¤¾, à¤®à¥à¤à¥‡ à¤•à¥€à¤¡à¤¼à¥‹à¤‚ à¤•à¥‹ à¤›à¥‚à¤¨à¥‡ à¤¸à¥‡ à¤•à¥‹à¤ˆ à¤ªà¤°...</td>
    </tr>
  </tbody>
</table>
<p>5548 rows Ã— 3 columns</p>



```python
logging.basicConfig(level=logging.INFO)
transformers_logger=logging.getLogger("transformers")
transformers_logger.setLevel(logging.WARNING)
```


```python
model_args = T5Args()
model_args.max_seq_length = 96           #maximum sequence length the model will support
model_args.train_batch_size = 29         #the training batch size
model_args.eval_batch_size = 20          #the evaluation batch size
model_args.num_train_epochs = 1                       #the number of epochs the model will be trained for
model_args.evaluate_during_training = False            #Set to True to perform evaluation while training models. Make sure eval data is passed to the training method if enabled.
#model_args.evaluate_during_training_steps = 100    #Perform evaluation at every specified number of steps. A checkpoint model and the evaluation results will be saved.
model_args.use_multiprocessing = False                #If True, multiprocessing will be used when converting data into features. Enabling can speed up processing, but may cause instability. Defaults to False.
model_args.fp16 = False                          #Whether or not fp16 mode should be used. Requires NVidia Apex library.
model_args.save_steps = -1                       #Save a model checkpoint at every specified number of steps. Set to -1 to disable.
model_args.save_eval_checkpoints = False         #Save a model checkpoint for every evaluation performed.
model_args.no_cache = True                       #Cache features to disk.
model_args.reprocess_input_data = True           #If True, the input data will be reprocessed even if a cached file of the input data exists in the cache_dir.
model_args.overwrite_output_dir = True           #If True, the trained model will be saved to the ouput_dir and will overwrite existing saved models in the same directory.
model_args.preprocess_inputs = False             #If preprocess_inputs is set to True in the model args, then the ` < /s> token (including preceeding space) is automatically added to each string in the list. Otherwise, the strings must have the  < /s>` (including preceeding space) must be included.
model_args.num_return_sequences = 1              #whether to do beam search or not
#model_args.wandb_project = "MT5 Sinhala-English Translation" #Name of W&B project. This will log all hyperparameter values, training losses, and evaluation metrics to the given project.

```


```python
model = T5Model("mt5", "google/mt5-base", args=model_args,use_cuda=False)
```


```python
model.train_model(train_df,eval_data=eval_df)
```

```python
results = model.eval_model(eval_df, verbose=True)
# If verbose, results will be printed to the console on completion of evaluation.
```
