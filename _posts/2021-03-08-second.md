---
layout: post
title: 시계열 데이터 분석 - 자기상관 진단,계절적 요소 처리
subtitle: 시계열 데이터 진단
tags: [시계열 데이터,자기회귀]
comment: True
---

## 공부하는 이유 + 출처

제가 데이터 분석에 관심이 있는 이유는 실생활과 관련된 날 것의 데이터 안에 좋은 인사이트가 숨겨져있을 수 있다는 생각 때문입니다. (헬스 시계열 데이터를 잘 활용하여 유의미한 분석을 해보고 싶습니다.) 현재 관련 개념을 보충하기 위해 유튜브로 김성범 교수님 강의를 듣고 있습니다. [2020년도 예측 모델 강의 ](https://www.youtube.com/watch?v=g2pXzSNwcAQ&list=PLpIPLT0Pf7IqSuMx237SHRdLd5ZA4AQwd) 오늘은 time regression 02 파트를 들었습니다. 😀

### 오차와 잔차 , 모형 가정

오차 : 실제 관측값 - **모집단**의 회귀 분석에서 예측된 값 

잔차 : 실제 관측값 - **표본집단**의 회귀 분석에서 예측된 값 

=> 아무리 노력해도 설명될 수 없는 고유성, 생략된 모든 미묘한 features

모형 가정 = 좋은 회귀선의 조건 

모형 가정은 여러 조건들을 담고 있는데 시계열 데이터와 가장 관련있는 조건은 **독립성 조건**입니다. 

독립성 조건 : 입력변수 (X) 간에 상관관계가 없어야 함을 뜻함

이고 일반적으로 오차가 통계적으로 독립적인 경우, X 도 독립성이 유지되므로 **COV(ei,ej) = 0** 이어야 함을 의미합니다.  *ei, ej = i 시점의 오차, j 시점의 오차를 의미합니다. 보통은 단순한게 판단하기 어렵기 때문에 **durbin-watson 통계량**을 이용해야지 정확하다고 합니다. 관련 내용은 뒤에 설명하겠습니다. 

이러한 **독립성 조건이 깨지고 오차항들이 어떠한 상관관계를 갖는 현상을 자기상관** 이라고 합니다. 



### Auto-correlation 이 발생한다면 ? 

자기  발생하면 어떠한 문제점이 발생하는지 알아보겠습니다. 

우선 어떠한 인풋 데이터를 가지고 회귀모델을 만들었다면  회귀선을 맞게 그렸는지를 알고 싶을 것입니다. = parameters 를 제대로 구했는지 알고 싶을 것입니다. 실제 정답값을 100% 한치의 오차도 없이 정확하게 예측할 수 있는 매개변수를 b  라고 하면, 구해준 회귀모델의 매개변수는 언제까지나 이에 근접하지만 도달하지는 못하는 b햇이 됩니다. 

그리고 좋은 회귀 모델을 결정하는 b햇 값을 제대로 구해준게 맞는지를 검증하기 위해서 t-test를 이용합니다. 

통계에서 확률 분포로 p-value 몇 인지 판단해줄 때의 분포는 결국 **차이 / 불확실성** 으로 이루어진 것입니다. t-분포도 마찬가지입니다. 이 부분은 공돌이의 수학 정리노트를 참고하였습니다. 

t-분포를 이용하기 위해 t-변환을 시켜보면 차이는 b햇과 b 의 차이이므로 **b햇 - b** 라고 쓸 수 있습니다. 

차이를 불확실성으로 나누어주는 이유는 **b햇은 언제까지나 예측값이므로 매번 바뀔 수 있고 그러면 b햇은 계속 바뀌는데 특정 b햇 값을 가지고만 b와 차이가 일반적으로 이 정도 난다고 나타나네 라고 분포를 구해주는 게 정확해 ?** 라는 클레임 때문입니다. 

그래서 좀 더 정확한 검증을 위해서 차이를 불확실성으로 나누어줘야하는데,  현재의 경우 t - 변환에서 불확실성은 SE(b햇) 이 됩니다. SE(b햇) 은 b햇의 표준오차이므로 자료가 변할 때마다 달라지는 b햇 값들이 평균적으로 퍼져있는 정도를 의미하기 때문입니다. 

따라서 t - test 를 하기 위한 t 변환 식은 **b햇 - b / SE(b햇)** 이 됩니다. 

그런데 ! 데이터가 비슷한 시점을 중심으로 cluster 을 형성하는 자기회귀 현상이 발생할 경우, 비슷한 데이터 (=클러스터를 형성한 데이터) 의 b햇들은 비슷하게 추정되니까 SE(b햇) 의 과소추정이 일어납니다. 

일반적으로는 데이터가 달라지면 절편과 기울기 값에 평균적으로 a 만큼의 변화가 있는게 맞는데, 자기회귀가 발생해서 데이터들이 서로 오밀조밀 비슷하다보니까 b햇의 추정값 자체의 폭이 과소추정되는 것입니다. 

따라서 **b햇 - b / SE(b햇)** 에서 분모인 SE(b햇) 이 정확 수치보다 과소추정되므로 실제 구해진 t-score 값도 정확히 나와야하는 t-score 값보다 커집니다. 

제대로 된 b햇 값이라면 실제 b와의 차이가 (<u>b햇</u> - b) 의 b햇 자리에 어떠한 값을 대입하더라도 흔하게 발생할 수 있는 값이 아니라 유의미하고 특수해야합니다. 즉  b햇 - b = x 일 확률이 t 분포에서 90% 이상이라면 해당 b햇은 다르게 찍었어도 그 정도 오차를 냈을 거기 때문에 제대로 구한 것이 아니라 그냥 아무거나 찍은 b햇 값임을 알 수 있습니다. 하지만 t-score 이 최종적으로 과대추정되면 이러한 1종 오류를 놓칠 가능성이 높아집니다. 

![IMG_FFC63CD87336-1](https://user-images.githubusercontent.com/67775336/110300419-30326680-803a-11eb-8dcd-2b212e9d2bef.jpeg)

(b햇을 추정하는 방법은 최소제곱법을 활용합니다)

### Durbin -watson test 로 자기상관진단

Negative autocorrelation : 현재의 오차항이 과거와 다른 부호를 가지려는 경향이 있음

Positive autocorrelation : 현재의 오차항이 과거와 같은 부호를 가지려는 경향이 있음

No autocorrelation : 현재의 오차항이 과거와는 무관하게 나타남 (=독립성의 조건)

Durbin-watson test 는 한 시점 이전의 값들간의 자기상관만 진단하는 한계가 있다고 합니다. 더 이전 시점의 값들간의 자기 상관을 진단하는 것은 추후 강의에서 더 공부할 수 있다고 합니다. 저는 이것만 해도 머리가 지끈거려서 🥺 지금은 네.. 그냥 좀 쉬고 싶어요 

그러면 durbin-watson test 로 우선 first-order positive autocorrelation 을 진단하는 방법은

![IMG_990E069CC825-1](https://user-images.githubusercontent.com/67775336/110301227-2b21e700-803b-11eb-8560-e0f3980eb80b.jpeg)

입니다. 교수님 강의 ppt 자료입니다 ! (제 자료가 아녜유) 

Durbin-watson test 는 신기한게 lower bound,upper bound 가 제공됩니다. 자기상관의 판단 척도가 되는 유의미한(p-value 0.05 미만의) lower bound,upper bound 값을 알려주는 것입니다. 

lower bound 보다 score 이 낮으면 오차 간의 차이가 매우 적고 오밀조밀한 것이므로 독립성의 조건을 만족한다는 귀무가설을 기각합니다. 

다음으로  durbin-watson test 로 우선 first-order negative autocorrelation 을 진단하는 방법은 

![IMG_4DA9EE48A817-1](https://user-images.githubusercontent.com/67775336/110301666-b00d0080-803b-11eb-9aad-4d350149b471.jpeg)

입니다. score 을 구하는 식이 좀 달라진 이유는 negative autocorrelation 이 발생하면 부호가 왔다갔다하므로 positive 의 상황과는 반대로 오차가 매우 커지기 때문입니다. 그래서 오차가 클수록 4-d 값은 작아지므로 이렇게 응용한 것 같습니다. 

이렇게 겉핥기로나마 durbin-watson test 를 시계열 데이터에서 어떻게 활용할 수 있는지를 알아보았습니다. 나중에 기회가 되면 나중에... durbin-watson test 에 대해 공부를 해볼 날 이 올까요 ? 



### increasing seasonal variations 처리 문제

다음으로 시계열 데이터에서 고려해야될 점은 seasonal variations 입니다. 주별,월별,계절별과 같이 주기적인 요인에 의한 변동으로 겨울에 비행기 예약건수가 급증했다가 봄에 급감하고 다시 여름에 급증했다가 가을에 급감하고 이러한 양상을 보인다고 할 수 있습니다. 

seasonal variation 이 매 시즌마다 일어나는 폭이 일정한 constant seasonal variations 의 경우 처리가 어렵지 않다고 합니다. 아직 seasonal variations 을 어떻게 처리할 수 있는지에 대해서는 배우지 못했습니다. 

그런데 매 시즌마다 보이는 양상은 같지만 폭이 점차 증가하는 increasing seasonal variations 의 경우 그 폭을 일정하게 조정을 해줄 필요가 있다고 합니다. (constant seasonal variations 화 시키기)

그렇게 하기 위해서는 점차 증가하는 데이터 값을 다시 작게 scaling 해주어야 합니다. 

y(t)* ; t 시점의 예측값을 re scaling 한 값 = ln y(t) 혹은 y(t)^0.5 입니다. 

즉 계속해서 증가하는 예측값에 루트를 씌워주거나 ln을 취해줘서 rescaling 해줍니다. 

![IMG_57FE1F9F1A90-1](https://user-images.githubusercontent.com/67775336/110302883-16dee980-803d-11eb-9c47-a0dff03200f7.jpeg)



### 통계를 더 공부할 필요성을 느끼면서 마무으리

수학을 잘하지도 않은 코찔찔이이지만 데이터 분석을 하기 위해서 필요한 통계 영역을 더 집중적으로 공부하면 큰 도움을 받을 수 있겠다라는 생각이 듭니다. 저는 2학기가 시작되어야만 정식 학생으로서 거취를 확정할 수가 있는데 ~~(왜 대학원을 이렇게 늦게 지원하고 인생 시기를 늦추느냐,그동안 뭐하느냐 엄청난 잔소리를 들었지만 아니 내 인생이 좀 슬로우라이프인가 보지..)~~ 통계 과목을 열심히 들으려고 다짐 중입니다. 
